\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\geometry{a4paper,margin=2.5cm}

\title{Especificación Técnica y Análisis de un Sistema de Identificación de Personas mediante Similitud Semántica en Descripciones Textuales}
\author{Investigadores en Ingeniería de Sistemas}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Este artículo presenta la especificación técnica completa de un sistema distribuido diseñado para identificar personas a partir de descripciones textuales mediante técnicas avanzadas de procesamiento del lenguaje natural y similitud semántica. El sistema implementa una arquitectura basada en microservicios que incluye componentes especializados para la recolección de datos, procesamiento, generación de embeddings vectoriales, almacenamiento y búsqueda semántica. Se detallan los aspectos arquitectónicos, los flujos de datos, los modelos de lenguaje natural utilizados, los mecanismos de comunicación entre servicios, la infraestructura de implementación y las interfaces de usuario. Además, se analizan los resultados experimentales que demuestran la eficacia del sistema en tareas de identificación de individuos a partir de descripciones textuales imprecisas o incompletas. El sistema representa un avance significativo en la aplicación de tecnologías semánticas para la identificación de personas en diversos contextos como seguridad, investigación forense, y sistemas de atención ciudadana.
\end{abstract}

\tableofcontents

\newpage

\section{Introducción}
\label{sec:introduccion}

La identificación de personas a partir de descripciones textuales representa un desafío significativo en múltiples dominios, incluyendo seguridad pública, investigación forense, atención a denuncias ciudadanas y localización de personas desaparecidas. Tradicionalmente, los sistemas de búsqueda de personas han dependido de criterios estructurados y coincidencias exactas, limitando su efectividad cuando las descripciones son imprecisas, incompletas o utilizan terminología variada. 

La capacidad humana para reconocer similitudes semánticas entre descripciones que utilizan diferentes palabras pero transmiten significados similares supera ampliamente a los sistemas computacionales convencionales. Por ejemplo, frases como "persona de estatura elevada, complexión delgada y cabello oscuro" y "individuo alto y flaco con pelo negro" describen características físicas equivalentes empleando vocabulario distinto. Los enfoques tradicionales basados en coincidencia de palabras clave fallarían en identificar esta similitud conceptual.

El avance reciente en modelos de lenguaje natural y técnicas de representación vectorial del significado (embeddings) ha abierto nuevas posibilidades para abordar este problema desde una perspectiva semántica. Estos modelos capturan las relaciones contextuales entre palabras y conceptos, permitiendo identificar similitudes significativas incluso cuando las descripciones utilizan terminología divergente.

El sistema presentado en este artículo aprovecha estos avances para implementar una arquitectura distribuida que aborda los siguientes objetivos:

\begin{itemize}
    \item Procesar y analizar descripciones textuales de personas en lenguaje natural.
    \item Generar representaciones vectoriales que capturen el significado semántico de las descripciones.
    \item Permitir búsquedas por similitud conceptual, no limitadas a coincidencias léxicas.
    \item Integrar fuentes de datos heterogéneas manteniendo un modelo unificado.
    \item Proporcionar interfaces intuitivas para la consulta y visualización de resultados.
    \item Escalar horizontalmente para manejar grandes volúmenes de datos y consultas concurrentes.
\end{itemize}

El sistema ha sido diseñado como una arquitectura de microservicios, donde cada componente tiene responsabilidades específicas y se comunica con otros mediante interfaces bien definidas. Esta aproximación facilita el mantenimiento, la extensibilidad y la resiliencia del sistema, permitiendo además la evolución independiente de cada componente según las necesidades del dominio.

En las siguientes secciones se detalla la arquitectura completa del sistema, incluyendo cada uno de sus componentes, los modelos de lenguaje natural empleados, los mecanismos de almacenamiento, las estrategias de búsqueda, y las interfaces de usuario. Adicionalmente, se presentan los resultados experimentales que validan la efectividad del enfoque propuesto en escenarios reales de identificación de personas.


\section{Servicio de Recolección de Datos (Data Harvester)}
\label{sec:data-harvester}

El servicio de recolección de datos representa el punto de entrada para la información en el sistema. Su principal responsabilidad es la extracción, transformación inicial y carga de datos relacionados con descripciones de personas desde múltiples fuentes heterogéneas. Este componente ha sido diseñado para manejar diversos formatos de entrada y adaptarse a diferentes estrategias de ingesta según la naturaleza de cada fuente.

\subsection{Arquitectura Interna}
\label{subsec:dh-arquitectura}

Internamente, el Data Harvester implementa una arquitectura modular basada en el patrón de adaptadores. Cada tipo de fuente de datos dispone de un adaptador especializado que conoce las particularidades de dicha fuente y se encarga de la extracción y normalización inicial de la información. Esta aproximación facilita la incorporación de nuevas fuentes de datos con mínimo impacto en el resto del sistema.

El servicio se estructura en los siguientes componentes principales:

\begin{itemize}
    \item \textbf{Orchestration Controller}: Coordina la ejecución de las tareas de recolección, gestiona la programación temporal de las extracciones recurrentes y monitoriza el estado de cada proceso.
    
    \item \textbf{Source Adapters}: Componentes especializados para cada tipo de fuente. Actualmente el sistema implementa adaptadores para:
    \begin{itemize}
        \item Bases de datos relacionales (MySQL, PostgreSQL)
        \item APIs REST
        \item Archivos estructurados (CSV, JSON, XML)
        \item Documentos no estructurados (PDF, DOC)
        \item Sistemas de almacenamiento en nube (S3, GCS)
    \end{itemize}
    
    \item \textbf{Data Mapper}: Transforma los datos extraídos al modelo canónico del sistema, asegurando una representación uniforme independientemente de la fuente original.
    
    \item \textbf{Validation Engine}: Aplica reglas de validación para garantizar la calidad y consistencia de los datos recolectados antes de su incorporación al flujo de procesamiento.
    
    \item \textbf{Queuing Service}: Gestiona la comunicación asíncrona con el Orchestrator, implementando patrones de publicación/suscripción.
    
    \item \textbf{Monitoring & Metrics}: Recopila métricas de rendimiento y estado del proceso de recolección para su posterior análisis.
\end{itemize}

\subsection{Modelo de Datos}
\label{subsec:dh-modelo-datos}

Para garantizar la interoperabilidad entre servicios, el Data Harvester transforma todos los datos recolectados a un modelo canónico que define la estructura estándar de una descripción de persona en el sistema. Este modelo incluye:

\begin{itemize}
    \item \textbf{Identificador único}: Generado mediante UUID v4 para cada registro.
    \item \textbf{Metadatos de origen}: Incluye fuente, timestamp de extracción, y parámetros de confiabilidad.
    \item \textbf{Datos estructurados}: Campos normalizados como edad, altura, género, cuando están disponibles explícitamente.
    \item \textbf{Descripción textual}: El contenido textual completo que describe a la persona.
    \item \textbf{Contenido multimedia}: Enlaces o referencias a imágenes, videos u otros contenidos multimedia asociados.
    \item \textbf{Relaciones}: Vínculos con otros registros que puedan representar a la misma persona.
    \item \textbf{Estado de procesamiento}: Seguimiento del progreso a través del pipeline de procesamiento.
\end{itemize}

Este modelo se serializa en formato JSON para su transmisión entre servicios, adoptando un esquema bien definido que facilita la validación y la evolución compatible.

\subsection{Estrategias de Extracción}
\label{subsec:dh-estrategias}

El Data Harvester implementa múltiples estrategias de extracción para optimizar el proceso según las características de cada fuente:

\subsubsection{Extracción Completa}
Utilizada para fuentes pequeñas o que requieren una sincronización total. Extrae todos los datos en cada ejecución, reemplazando completamente la versión anterior.

\subsubsection{Extracción Incremental}
Para fuentes de mayor volumen que soportan filtrado por fecha de modificación. Solo extrae registros nuevos o modificados desde la última ejecución.

\subsubsection{Extracción por Lotes}
Divide la extracción en bloques más pequeños para minimizar el impacto en la fuente y en los recursos del sistema. Particularmente útil en fuentes con limitaciones de rendimiento o cuotas de acceso.

\subsubsection{Extracción Basada en Eventos}
Para fuentes que implementan mecanismos de notificación. El sistema se suscribe a eventos de cambio y reactivamente procesa las modificaciones cuando se producen.

\subsection{Mecanismos de Resiliencia}
\label{subsec:dh-resiliencia}

La recolección de datos desde fuentes heterogéneas presenta numerosos desafíos de fiabilidad. El Data Harvester implementa varios mecanismos para garantizar la robustez del proceso:

\begin{itemize}
    \item \textbf{Reintentos con backoff exponencial}: Para manejar errores transitorios en la comunicación con fuentes externas.
    
    \item \textbf{Circuit breaker}: Evita sobrecargar fuentes que están experimentando problemas, deteniendo temporalmente las solicitudes cuando se detecta un patrón de fallos.
    
    \item \textbf{Checkpointing}: Registra el progreso de extracciones largas, permitiendo reanudar desde el último punto conocido en caso de interrupción.
    
    \item \textbf{Colas de dead-letter}: Capturan registros que no pueden ser procesados correctamente para su posterior análisis y recuperación manual.
    
    \item \textbf{Validación predictiva}: Anticipando posibles errores mediante la validación temprana de la disponibilidad y estructura de la fuente antes de iniciar una extracción completa.
\end{itemize}

\subsection{Implementación Técnica}
\label{subsec:dh-implementacion}

El Data Harvester está implementado como una aplicación en Python 3.9, aprovechando las siguientes tecnologías:

\begin{itemize}
    \item \textbf{Framework principal}: FastAPI para la exposición de endpoints REST y la integración con tareas asíncronas.
    
    \item \textbf{ORM}: SQLAlchemy para la interacción con bases de datos relacionales, facilitando la abstracción sobre diferentes motores de bases de datos.
    
    \item \textbf{Procesamiento asíncrono}: Celery para la ejecución de tareas en segundo plano, con Redis como broker de mensajes.
    
    \item \textbf{Validación de datos}: Pydantic para la definición y validación de esquemas.
    
    \item \textbf{Integración con Kafka}: Confluent-Kafka-Python para la publicación de eventos hacia el Orchestrator.
    
    \item \textbf{Extracción de documentos}: Bibliotecas especializadas como PyPDF2, python-docx y BeautifulSoup para la extracción de contenido textual de diferentes formatos de documentos.
    
    \item \textbf{Monitorización}: Prometheus client para la exposición de métricas, complementado con logging estructurado en formato JSON.
\end{itemize}

El servicio se despliega como un contenedor Docker basado en la imagen oficial de Python, con las dependencias gestionadas mediante Poetry para garantizar entornos reproducibles.

\subsection{Escalabilidad y Rendimiento}
\label{subsec:dh-escalabilidad}

Para manejar grandes volúmenes de datos y múltiples fuentes concurrentes, el Data Harvester implementa varias estrategias de escalabilidad:

\begin{itemize}
    \item \textbf{Paralelización de extracciones}: Diferentes fuentes pueden ser procesadas simultáneamente por instancias independientes del servicio.
    
    \item \textbf{Procesamiento por lotes}: Las extracciones grandes se dividen automáticamente en lotes más pequeños que pueden ser procesados en paralelo.
    
    \item \textbf{Throttling adaptativo}: Ajusta dinámicamente la velocidad de extracción basándose en la respuesta y capacidad de la fuente.
    
    \item \textbf{Programación de extracciones}: Distribuye las tareas recurrentes en diferentes momentos para evitar picos de carga.
    
    \item \textbf{Priorización de colas}: Implementa múltiples colas con diferentes prioridades para optimizar la utilización de recursos.
\end{itemize}

En términos de rendimiento, el servicio ha sido optimizado para procesar aproximadamente 1,000 registros por segundo en extracciones de bases de datos relacionales, y entre 50-200 documentos por minuto en el caso de extracción de contenido desde documentos no estructurados.

\section{Servicio de Autenticación (Auth Service)}
\label{sec:auth-service}

El Servicio de Autenticación constituye un componente fundamental para garantizar la seguridad y el control de acceso en todo el sistema. Este servicio centraliza las funciones de autenticación, autorización y gestión de identidades, proporcionando un enfoque coherente y robusto de seguridad a través de todos los microservicios que componen la plataforma.

\subsection{Funcionalidades Principales}
\label{subsec:as-funcionalidades}

El Auth Service proporciona las siguientes capacidades esenciales:

\begin{itemize}
    \item \textbf{Autenticación de usuarios}: Verificación de identidades mediante múltiples métodos, asegurando que solo usuarios legítimos puedan acceder al sistema.
    
    \item \textbf{Gestión de sesiones}: Creación, mantenimiento y revocación de sesiones de usuario, controlando el ciclo de vida del acceso al sistema.
    
    \item \textbf{Autorización granular}: Control preciso sobre qué recursos puede acceder cada usuario, implementando modelos de permisos sofisticados.
    
    \item \textbf{Federación de identidades}: Integración con proveedores externos de identidad, facilitando experiencias de inicio de sesión único (SSO).
    
    \item \textbf{API segura para servicios}: Autenticación y autorización para comunicaciones entre microservicios internos del sistema.
    
    \item \textbf{Auditoría de seguridad}: Registro detallado de todas las operaciones relacionadas con acceso y permisos.
    
    \item \textbf{Gestión de tokens}: Emisión, validación y revocación de tokens de acceso, utilizando estándares como JWT (JSON Web Tokens).
\end{itemize}

\subsection{Arquitectura de Seguridad}
\label{subsec:as-arquitectura}

El Auth Service implementa una arquitectura basada en estándares modernos de seguridad, con los siguientes componentes principales:

\begin{itemize}
    \item \textbf{Identity Provider (IdP)}: Núcleo del servicio, responsable de la autenticación y mantenimiento de identidades de usuario.
    
    \item \textbf{OAuth2 Authorization Server}: Implementa el flujo completo de OAuth 2.0, permitiendo la delegación segura de acceso.
    
    \item \textbf{OpenID Connect Provider}: Extiende OAuth 2.0 con funcionalidades de identidad, proporcionando información verificada sobre los usuarios.
    
    \item \textbf{Token Service}: Gestiona la emisión, validación y revocación de tokens de acceso y refresco.
    
    \item \textbf{Policy Enforcement Point (PEP)}: Puntos de control que interceptan solicitudes para verificar permisos antes de permitir el acceso a recursos.
    
    \item \textbf{Policy Decision Point (PDP)}: Motor de evaluación de políticas que determina si una solicitud debe ser permitida según las políticas configuradas.
    
    \item \textbf{Policy Administration Point (PAP)}: Interfaz para gestionar y configurar políticas de seguridad.
    
    \item \textbf{User Directory}: Almacén seguro para información de usuarios, roles, grupos y atributos.
    
    \item \textbf{Audit Logger}: Componente dedicado a registrar de forma inmutable todas las operaciones relacionadas con seguridad.
\end{itemize}

\subsection{Modelos de Autenticación}
\label{subsec:as-autenticacion}

El servicio soporta múltiples métodos de autenticación para adaptarse a diferentes requisitos de seguridad y experiencia de usuario:

\begin{itemize}
    \item \textbf{Autenticación basada en credenciales}:
    \begin{itemize}
        \item Usuario/contraseña con políticas robustas de complejidad y caducidad
        \item Protección contra ataques de fuerza bruta mediante bloqueo progresivo
        \item Almacenamiento seguro de contraseñas mediante algoritmos de hash modernos (Argon2id)
    \end{itemize}
    
    \item \textbf{Autenticación multifactor (MFA)}:
    \begin{itemize}
        \item Códigos temporales (TOTP) mediante aplicaciones como Google Authenticator
        \item Verificación por SMS o correo electrónico
        \item Llaves de seguridad físicas compatibles con FIDO2/WebAuthn
        \item Notificaciones push a dispositivos verificados
    \end{itemize}
    
    \item \textbf{Autenticación federada}:
    \begin{itemize}
        \item Integración con proveedores de identidad corporativos (Active Directory, Azure AD)
        \item Soporte para proveedores SAML 2.0
        \item Autenticación social (Google, Microsoft, GitHub) para ciertos niveles de acceso
    \end{itemize}
    
    \item \textbf{Autenticación para servicios}:
    \begin{itemize}
        \item Autenticación mutua TLS (mTLS) para comunicaciones entre servicios
        \item Secretos compartidos y API keys para integraciones externas
        \item OAuth 2.0 Client Credentials para aplicaciones máquina-a-máquina
    \end{itemize}
\end{itemize}

\subsection{Modelo de Autorización}
\label{subsec:as-autorizacion}

El sistema implementa un modelo de autorización sofisticado basado en múltiples estrategias complementarias:

\subsubsection{Control de Acceso Basado en Roles (RBAC)}
Define permisos agrupados en roles que luego se asignan a usuarios:

\begin{itemize}
    \item Roles predefinidos con conjuntos específicos de permisos (Administrador, Analista, Operador, Auditor, etc.)
    \item Jerarquía de roles que permite herencia de permisos
    \item Separación de funciones (SoD) para prevenir conflictos de interés
    \item Asignación dinámica de roles basada en contexto organizacional
\end{itemize}

\subsubsection{Control de Acceso Basado en Atributos (ABAC)}
Permite decisiones de acceso más flexibles basadas en atributos del usuario, recurso, acción y entorno:

\begin{itemize}
    \item Evaluación de políticas basadas en múltiples atributos (departamento, nivel de clearance, ubicación, hora del día)
    \item Políticas expresadas en lenguaje declarativo usando ALFA (lenguaje de políticas basado en XACML)
    \item Evaluación contextual que considera el estado del sistema y metadatos de la solicitud
    \item Soporte para condiciones complejas y operadores booleanos
\end{itemize}

\subsubsection{Control de Acceso Basado en Relaciones (ReBAC)}
Particularmente relevante para el dominio de identificación de personas:

\begin{itemize}
    \item Permisos basados en la relación entre el usuario y los datos (propietario, supervisor, colaborador)
    \item Propagación controlada de permisos a través de relaciones definidas
    \item Restricciones de visibilidad basadas en jurisdicción, caso o proyecto
\end{itemize}

\subsection{Gestión de Tokens y Sesiones}
\label{subsec:as-tokens}

El servicio implementa una estrategia robusta para la gestión de tokens de acceso:

\begin{itemize}
    \item \textbf{Estructura de tokens}: JWT firmados digitalmente que contienen:
    \begin{itemize}
        \item Identificación del usuario (sub)
        \item Ámbito de acceso (scope)
        \item Tiempo de emisión y expiración
        \item Contexto de autenticación (método utilizado, nivel de confianza)
        \item Claims específicos relevantes para autorización
    \end{itemize}
    
    \item \textbf{Ciclo de vida de tokens}:
    \begin{itemize}
        \item Tokens de acceso de corta duración (15-60 minutos)
        \item Tokens de refresco de duración media con rotación (24 horas - 7 días)
        \item Mecanismo de revocación basado en listas negras distribuidas
        \item Validación de integridad mediante firmas RS256
    \end{itemize}
    
    \item \textbf{Estrategia de sesiones}:
    \begin{itemize}
        \item Sesiones distribuidas almacenadas en Redis
        \item Timeout adaptativo basado en actividad y riesgo
        \item Limitación configurable de sesiones concurrentes
        \item Terminación forzada de sesiones ante cambios de permisos críticos
    \end{itemize}
\end{itemize}

\subsection{Seguridad a Nivel de API}
\label{subsec:as-api-security}

Todas las APIs del sistema, tanto externas como entre microservicios, implementan múltiples capas de seguridad:

\begin{itemize}
    \item \textbf{Protección perimetral}:
    \begin{itemize}
        \item TLS 1.3 obligatorio para todas las comunicaciones
        \item HTTP Security Headers (HSTS, CSP, X-Content-Type-Options)
        \item Protección contra ataques CSRF mediante tokens específicos
        \item Limitación de tasa adaptativa para prevenir abusos
    \end{itemize}
    
    \item \textbf{Validación de entradas}:
    \begin{itemize}
        \item Esquemas de validación estrictos con JSON Schema
        \item Sanitización de entradas para prevenir inyecciones
        \item Validación contextual que considera el estado y la coherencia
    \end{itemize}
    
    \item \textbf{Comunicación entre servicios}:
    \begin{itemize}
        \item mTLS para autenticación mutua entre microservicios
        \item Verificación de origen mediante network policies
        \item Tokens de servicio con ámbito limitado y duración corta
    \end{itemize}
\end{itemize}

\subsection{Auditoría y Cumplimiento}
\label{subsec:as-auditoria}

El sistema implementa capacidades avanzadas de auditoría para satisfacer requisitos regulatorios y de cumplimiento:

\begin{itemize}
    \item \textbf{Registro inmutable}: Todas las operaciones de autenticación, autorización y gestión de identidades se registran en logs inmutables.
    
    \item \textbf{Eventos auditados}:
    \begin{itemize}
        \item Intentos de autenticación (exitosos y fallidos)
        \item Cambios en permisos o roles
        \item Acceso a datos sensibles
        \item Modificaciones de políticas de seguridad
        \item Creación, modificación y eliminación de cuentas
        \item Eventos administrativos (configuración, mantenimiento)
    \end{itemize}
    
    \item \textbf{Detalles de registros}:
    \begin{itemize}
        \item Timestamp preciso con sincronización NTP
        \item Identificación del actor (usuario o servicio)
        \item Acción realizada y resultado
        \item Recursos afectados
        \item Contexto (dirección IP, dispositivo, ubicación)
        \item Identificador de correlación para seguimiento de operaciones
    \end{itemize}
    
    \item \textbf{Alertas y monitorización}:
    \begin{itemize}
        \item Detección de patrones anómalos o sospechosos
        \item Alertas en tiempo real para eventos críticos
        \item Paneles de visualización para análisis de tendencias
    \end{itemize}
\end{itemize}

\subsection{Implementación Técnica}
\label{subsec:as-implementacion}

El Auth Service está implementado utilizando tecnologías modernas y probadas en el ámbito de la seguridad:

\begin{itemize}
    \item \textbf{Plataforma base}: Keycloak (Red Hat SSO) con extensiones personalizadas para requisitos específicos del dominio.
    
    \item \textbf{Lenguajes principales}:
    \begin{itemize}
        \item Java para componentes core de Keycloak
        \item Kotlin para extensiones y servicios personalizados
        \item Go para componentes de alto rendimiento (validación de tokens)
    \end{itemize}
    
    \item \textbf{Almacenamiento de datos}:
    \begin{itemize}
        \item PostgreSQL para datos principales de usuarios y configuración
        \item Redis para gestión de sesiones y cachés de tokens
        \item Kafka para eventos de auditoría y notificaciones
    \end{itemize}
    
    \item \textbf{Infraestructura criptográfica}:
    \begin{itemize}
        \item Gestión de claves mediante HashiCorp Vault
        \item Algoritmos de firma: RS256, ES384
        \item Algoritmos de hash para contraseñas: Argon2id
        \item TLS 1.3 con Perfect Forward Secrecy
    \end{itemize}
    
    \item \textbf{Integración y automatización}:
    \begin{itemize}
        \item OpenAPI para documentación y generación de clientes
        \item Terraform para aprovisionamiento de infraestructura
        \item Automated security testing con OWASP ZAP y otros
    \end{itemize}
\end{itemize}

\subsection{Alta Disponibilidad y Recuperación}
\label{subsec:as-disponibilidad}

Dada la criticidad del servicio de autenticación, se implementan estrategias específicas para garantizar su disponibilidad:

\begin{itemize}
    \item \textbf{Arquitectura multi-nodo}: Despliegue en múltiples instancias con balanceo de carga.
    
    \item \textbf{Replicación síncrona}: Para datos críticos de autenticación y autorización.
    
    \item \textbf{Degradación elegante}: Capacidad para operar con funcionalidad reducida ante fallos parciales.
    
    \item \textbf{Circuit-breakers}: Protección contra fallos en cascada en integraciones con sistemas externos.
    
    \item \textbf{Diseño activo-activo}: Todas las instancias pueden servir solicitudes, eliminando puntos únicos de fallo.
    
\end{itemize}

\subsection{Estrategias de Resiliencia}
\label{subsec:as-resiliencia}

El servicio implementa diversos mecanismos para garantizar su robustez y disponibilidad:

\begin{itemize}
    \item \textbf{Manejo Estructurado de Excepciones}: Implementa una jerarquía de excepciones específicas del dominio que facilitan la identificación y gestión de diferentes tipos de errores.
    
    \item \textbf{Timeouts Configurables}: Establece límites de tiempo para operaciones externas, evitando bloqueos indefinidos.
    
    \item \textbf{Validación Exhaustiva}: Verifica la validez de todas las entradas antes de procesarlas, previniendo errores durante la ejecución.
    
    \item \textbf{Logging Detallado}: Registra información detallada sobre operaciones y errores, facilitando el diagnóstico y resolución de problemas.
    
    \item \textbf{Degradación Elegante}: Capacidad para operar con funcionalidad reducida ante fallos parciales.
    
\end{itemize}

Estos mecanismos aseguran que el servicio pueda operar de manera confiable incluso en presencia de condiciones adversas como alta carga, conectividad intermitente o fallos parciales del sistema.

\subsection{Extensibilidad y Evolución Futura}
\label{subsec:as-extension}

El diseño del servicio de autenticación facilita su extensión y evolución futura en varias direcciones:

\begin{itemize}
    \item \textbf{Autenticación Multifactor}: La arquitectura permite incorporar métodos adicionales de verificación como TOTP o códigos enviados por email/SMS.
    
    \item \textbf{Federación de Identidad}: Posibilidad de integrar proveedores externos como OAuth2/OpenID Connect.
    
    \item \textbf{Autorización Avanzada}: Evolución hacia modelos más sofisticados como ABAC (Attribute-Based Access Control) o ReBAC (Relationship-Based Access Control).
    
    \item \textbf{Gestión de Consentimiento}: Implementación de mecanismos para gestionar explícitamente el consentimiento del usuario sobre el uso de sus datos.
    
    \item \textbf{Auditoría Avanzada}: Registro detallado de todas las operaciones relacionadas con seguridad para cumplimiento y forense.
\end{itemize}

La arquitectura hexagonal adoptada facilita estas extensiones al permitir modificar componentes específicos sin afectar al resto del sistema.

\section{Servicio de Búsqueda (Search Service)}
\label{sec:search-service}

El Servicio de Búsqueda representa el componente neurálgico del sistema, responsable de implementar los algoritmos y técnicas que permiten recuperar perfiles de personas basados en la similitud semántica con una descripción de consulta. Este servicio materializa la capacidad fundamental del sistema para encontrar coincidencias basadas en significado, no solo en coincidencias léxicas.

\subsection{Objetivos y Responsabilidades}
\label{subsec:ss-objetivos}

El servicio de búsqueda ha sido diseñado para cumplir con los siguientes objetivos principales:

\begin{itemize}
    \item Proporcionar búsquedas semánticas de alta precisión utilizando vectores de embedding.
    
    \item Implementar múltiples estrategias de búsqueda adaptadas a diferentes necesidades (semántica, por palabras clave, híbrida).
    
    \item Ofrecer mecanismos de búsqueda eficientes y escalables para grandes volúmenes de datos.
    
    \item Facilitar la integración con diferentes modelos de embedding y tecnologías de bases de datos vectoriales.
    
    \item Proporcionar APIs flexibles que permitan configurar parámetros de búsqueda según las necesidades específicas.
\end{itemize}

\subsection{Arquitectura Interna}
\label{subsec:ss-arquitectura-interna}

El servicio implementa una arquitectura hexagonal (ports and adapters) que separa claramente el dominio de la aplicación de la infraestructura. Esta arquitectura se organiza en tres capas principales:

\begin{itemize}
    \item \textbf{Capa de Dominio}: Define las entidades fundamentales (SearchResult, SearchResults, EmbeddingVector, EmbeddingCollection), los contratos de repositorio (SearchRepository, EmbeddingRepository), y los objetos de valor (SearchRequest, EmbeddingRequest) que modelan el núcleo del servicio.
    
    \item \textbf{Capa de Aplicación}: Implementa el servicio principal (SearchService) que orquesta las operaciones de búsqueda y generación de embeddings, aplicando la lógica de negocio y coordinando las interacciones entre componentes.
    
    \item \textbf{Capa de Infraestructura}: Proporciona implementaciones concretas de los repositorios utilizando tecnologías específicas como FAISS para búsqueda vectorial, e integra diferentes estrategias de generación de embeddings mediante un patrón de estrategia.
\end{itemize}

Esta arquitectura facilita la evolución independiente de los componentes y permite la sustitución de tecnologías específicas sin afectar al núcleo del sistema.

\subsection{Modelo de Datos}
\label{subsec:ss-modelo-datos}

El servicio gestiona un modelo de datos centrado en los siguientes conceptos:

\begin{itemize}
    \item \textbf{EmbeddingVector}: Representa un vector de embedding junto con su texto original y metadatos asociados.
    \begin{itemize}
        \item Vector numérico de alta dimensionalidad (típicamente 384-1536 dimensiones)
        \item Texto original del que se derivó el embedding
        \item Metadatos asociados para enriquecer los resultados de búsqueda
        \item Identificador único que permite relacionarlo con datos en otros servicios
    \end{itemize}
    
    \item \textbf{EmbeddingCollection}: Agrupa un conjunto de vectores de embedding relacionados con un dataset específico.
    \begin{itemize}
        \item Colección de EmbeddingVector
        \item Referencia al dataset de origen
        \item Dimensionalidad de los vectores
        \item Métodos para manipular y consultar la colección
    \end{itemize}
    
    \item \textbf{SearchResult}: Representa un resultado individual de una búsqueda.
    \begin{itemize}
        \item Identificador único
        \item Texto original
        \item Puntuación de similitud (score)
        \item Metadatos asociados
        \item Datos completos del registro encontrado
    \end{itemize}
    
    \item \textbf{SearchResults}: Agrupa un conjunto de resultados de búsqueda junto con metadatos de la operación.
    \begin{itemize}
        \item Consulta original
        \item Colección de SearchResult
        \item Tiempo de ejecución
        \item Identificador único de la búsqueda
        \item Referencia al dataset consultado
    \end{itemize}
\end{itemize}

Este modelo proporciona la flexibilidad necesaria para representar y manipular eficientemente los datos vectoriales y los resultados de búsqueda.

\subsection{Estrategias de Búsqueda}
\label{subsec:ss-estrategias}

El servicio implementa múltiples estrategias de búsqueda que pueden seleccionarse según las necesidades específicas de cada consulta:

\begin{itemize}
    \item \textbf{Búsqueda Semántica}: Utiliza vectores de embedding para encontrar textos semánticamente similares a la consulta, independientemente de la coincidencia exacta de términos.
    \begin{itemize}
        \item Genera el embedding de la consulta utilizando el modelo especificado
        \item Utiliza FAISS (Facebook AI Similarity Search) para realizar búsqueda aproximada de vecinos más cercanos (ANN)
        \item Calcula la similitud mediante distancia L2 o producto escalar (según configuración)
        \item Ordena los resultados por puntuación de similitud
    \end{itemize}
    
    \item \textbf{Búsqueda por Palabras Clave}: Implementa búsqueda tradicional basada en coincidencia de términos.
    \begin{itemize}
        \item Utiliza TF-IDF (Term Frequency-Inverse Document Frequency) para representar documentos y consultas
        \item Calcula similitud mediante coseno entre vectores TF-IDF
        \item Prioriza documentos que contienen los términos exactos de la consulta
    \end{itemize}
    
    \item \textbf{Búsqueda Híbrida}: Combina búsqueda semántica y por palabras clave para aprovechar las fortalezas de ambos enfoques.
    \begin{itemize}
        \item Ejecuta ambas estrategias de búsqueda en paralelo
        \item Combina los resultados mediante un parámetro alpha configurable (0.5 por defecto)
        \item Permite ajustar el balance entre similitud semántica y coincidencia de términos
        \item Proporciona metadatos adicionales sobre las puntuaciones individuales de cada estrategia
    \end{itemize}
\end{itemize}

Estas estrategias proporcionan flexibilidad para adaptarse a diferentes escenarios de búsqueda y tipos de consultas.

\subsection{Integración con Modelos de Embedding}
\label{subsec:ss-modelos}

El servicio implementa un patrón de estrategia para soportar múltiples tecnologías de generación de embeddings:

\begin{itemize}
    \item \textbf{Sentence Transformers}: Implementación principal basada en la biblioteca sentence-transformers.
    \begin{itemize}
        \item Soporte para modelos multilingües como paraphrase-multilingual-MiniLM-L12-v2
        \item Procesamiento por lotes para optimizar rendimiento
        \item Normalización L2 de vectores resultantes
    \end{itemize}
    
    \item \textbf{Universal Sentence Encoder}: Alternativa basada en TensorFlow.
    \begin{itemize}
        \item Implementación mediante TensorFlow Hub
        \item Optimizado para consultas en tiempo real
        \item Soporte para múltiples idiomas
    \end{itemize}
    
    \item \textbf{BERT}: Implementación basada en modelos BERT de Hugging Face.
    \begin{itemize}
        \item Extracción de embeddings mediante mean pooling de la última capa oculta
        \item Soporte para diversos modelos pre-entrenados
        \item Aceleración mediante GPU cuando está disponible
    \end{itemize}
    
    \item \textbf{OpenAI}: Integración con la API de embeddings de OpenAI.
    \begin{itemize}
        \item Soporte para modelos como text-embedding-ada-002 y text-embedding-3-small/large
        \item Gestión de rate limiting y reintentos
        \item Caché de resultados para optimizar costos
    \end{itemize}
\end{itemize}

Esta arquitectura extensible permite incorporar fácilmente nuevos modelos de embedding a medida que evolucionan las tecnologías de procesamiento de lenguaje natural.

\subsection{Integración con Servicios Externos}
\label{subsec:ss-integracion}

El servicio de búsqueda interactúa con otros componentes del sistema para proporcionar funcionalidad completa:

\begin{itemize}
    \item \textbf{Servicio de Embedding}: Obtiene vectores pre-calculados para datasets completos, evitando la necesidad de regenerarlos en cada búsqueda.
    
    \item \textbf{Servicio de Almacenamiento de Datos}: Recupera información detallada sobre los registros encontrados, enriqueciendo los resultados de búsqueda con datos completos.
    
    \item \textbf{Servicio de Autenticación}: Verifica la identidad y permisos de los usuarios que realizan consultas (actualmente desactivado en el código pero preparado para su integración).
\end{itemize}

Estas integraciones se realizan mediante comunicación asíncrona a través de HTTP, utilizando la biblioteca httpx para realizar solicitudes eficientes.

\subsection{API y Comunicación}
\label{subsec:ss-api}

El servicio expone una API REST completa implementada con FastAPI, que proporciona las siguientes funcionalidades:

\begin{itemize}
    \item \textbf{Búsqueda}:
    \begin{itemize}
        \item POST /search: Realiza una búsqueda en un dataset específico con múltiples parámetros configurables
        \item Parámetros: query, dataset\_id, limit, search\_type, embedding\_model, hybrid\_alpha
        \item Retorna resultados detallados con puntuaciones y datos completos
    \end{itemize}
    
    \item \textbf{Generación de Embeddings}:
    \begin{itemize}
        \item POST /search/embeddings: Genera embeddings para una lista de textos
        \item Parámetros: texts, model, batch\_size, additional\_params
        \item Útil para aplicaciones cliente que necesitan vectores para procesamiento local
    \end{itemize}
    
    \item \textbf{Gestión de Modelos}:
    \begin{itemize}
        \item GET /search/models: Lista todos los modelos de embedding disponibles
        \item GET /search/models/{model\_name}: Obtiene información detallada sobre un modelo específico
    \end{itemize}
\end{itemize}

La API implementa manejo robusto de errores, validación de entrada, y documentación automática mediante Swagger UI.

\subsection{Implementación Técnica}
\label{subsec:ss-implementacion}

El servicio está implementado como una aplicación Python que utiliza las siguientes tecnologías clave:

\begin{itemize}
    \item \textbf{FastAPI}: Framework web de alto rendimiento para la implementación de la API REST.
    
    \item \textbf{FAISS}: Biblioteca de Facebook AI para búsqueda eficiente de similitud en espacios vectoriales de alta dimensionalidad.
    
    \item \textbf{Sentence Transformers}: Para la generación de embeddings de alta calidad.
    
    \item \textbf{NumPy}: Para operaciones eficientes con arrays numéricos.
    
    \item \textbf{Scikit-learn}: Utilizado para implementar la búsqueda basada en TF-IDF.
    
    \item \textbf{httpx}: Cliente HTTP asíncrono para comunicación con otros servicios.
\end{itemize}

El servicio se despliega como un contenedor Docker, facilitando su integración en la arquitectura de microservicios del sistema completo.

\subsection{Mecanismos de Optimización}
\label{subsec:ss-optimizacion}

Para garantizar un rendimiento óptimo, el servicio implementa diversas estrategias de optimización:

\begin{itemize}
    \item \textbf{Caché de Índices y Embeddings}: Mantiene en memoria los índices FAISS y colecciones de embeddings para datasets frecuentemente consultados.
    
    \item \textbf{Procesamiento Asíncrono}: Utiliza operaciones asíncronas para maximizar el throughput y minimizar la latencia, especialmente en comunicaciones con servicios externos.
    
    \item \textbf{Procesamiento por Lotes}: Agrupa múltiples textos para generación eficiente de embeddings, aprovechando el paralelismo de las operaciones vectoriales.
    
    \item \textbf{Búsqueda Aproximada}: Utiliza algoritmos de búsqueda aproximada de vecinos más cercanos (ANN) para mantener tiempos de respuesta constantes incluso con grandes volúmenes de datos.
    
    \item \textbf{Normalización de Vectores}: Pre-normaliza los vectores para optimizar cálculos de similitud durante la búsqueda.
\end{itemize}

Estas optimizaciones permiten que el servicio maneje eficientemente grandes volúmenes de datos mientras mantiene tiempos de respuesta bajos y un uso eficiente de los recursos del sistema.

\subsection{Estrategias de Resiliencia}
\label{subsec:ss-resiliencia}

El servicio implementa diversos mecanismos para garantizar su robustez y disponibilidad:

\begin{itemize}
    \item \textbf{Manejo Estructurado de Excepciones}: Implementa una jerarquía de excepciones específicas del dominio que facilitan la identificación y gestión de diferentes tipos de errores.
    
    \item \textbf{Timeouts Configurables}: Establece límites de tiempo para operaciones externas, evitando bloqueos indefinidos.
    
    \item \textbf{Validación Exhaustiva}: Verifica la validez de todas las entradas antes de procesarlas, previniendo errores durante la ejecución.
    
    \item \textbf{Logging Detallado}: Registra información detallada sobre operaciones y errores, facilitando el diagnóstico y resolución de problemas.
    
    \item \textbf{Degradación Elegante}: Capacidad para operar con funcionalidad reducida ante fallos parciales.
    
\end{itemize}

Estos mecanismos aseguran que el servicio pueda operar de manera confiable incluso en presencia de condiciones adversas como alta carga, conectividad intermitente o fallos parciales del sistema.

\subsection{Extensibilidad y Evolución Futura}
\label{subsec:ss-extension}

El diseño del servicio de búsqueda facilita su extensión y evolución futura en varias direcciones:

\begin{itemize}
    \item \textbf{Nuevos Modelos de Embedding}: La arquitectura basada en el patrón de estrategia permite incorporar fácilmente nuevos modelos de embedding a medida que se desarrollan.
    
    \item \textbf{Algoritmos de Búsqueda Avanzados}: La abstracción del repositorio de búsqueda facilita la implementación de nuevos algoritmos y técnicas de búsqueda.
    
    \item \textbf{Integración con Bases de Datos Vectoriales}: El diseño permite reemplazar FAISS con otras tecnologías como Pinecone, Weaviate o Qdrant sin afectar la lógica de negocio.
    
    \item \textbf{Búsqueda Multimodal}: La arquitectura puede extenderse para soportar búsqueda en múltiples modalidades (texto, imágenes, audio) mediante la incorporación de estrategias adicionales.
    
    \item \textbf{Personalización de Resultados}: El sistema está preparado para incorporar mecanismos de personalización basados en el contexto del usuario y su historial de interacciones.
\end{itemize}

Esta flexibilidad asegura que el servicio pueda adaptarse a nuevos requisitos y tecnologías emergentes sin necesidad de rediseños fundamentales.

\section{Servicio de Orquestación (Orchestrator) e Integración del Sistema}
\label{sec:orchestrator-service}

El Servicio de Orquestación representa el componente central que integra y coordina todos los microservicios del sistema, actuando como punto de entrada único y facilitando la comunicación entre los diferentes componentes. Este servicio implementa el patrón de API Gateway, proporcionando una fachada unificada que simplifica la arquitectura desde la perspectiva de los clientes y asegura una integración coherente del sistema.

\subsection{Objetivos y Responsabilidades}
\label{subsec:os-objetivos}

El servicio de orquestación ha sido diseñado para cumplir con los siguientes objetivos principales:

\begin{itemize}
    \item Proporcionar un punto de entrada único para todas las solicitudes al sistema, simplificando la arquitectura de cara a los clientes.
    
    \item Implementar un enrutamiento inteligente que dirija cada solicitud al microservicio correspondiente.
    
    \item Facilitar la evolución independiente de los servicios back-end sin afectar a los clientes.
    
    \item Ofrecer una capa de abstracción que oculte la complejidad interna de la arquitectura de microservicios.
    
    \item Centralizar aspectos transversales como registro, monitorización y control de acceso.
    
    \item Proporcionar una API unificada y coherente para los consumidores externos.
    
    \item Facilitar la escalabilidad y mantenimiento del sistema completo.
\end{itemize}

\subsection{Arquitectura Interna}
\label{subsec:os-arquitectura-interna}

El orquestador implementa una arquitectura de proxy inverso que redirige dinámicamente las solicitudes entrantes al microservicio apropiado. Esta arquitectura se caracteriza por:

\begin{itemize}
    \item \textbf{Diseño Minimalista}: Se centra exclusivamente en la función de enrutamiento, delegando la lógica de negocio a los microservicios especializados.
    
    \item \textbf{Enrutamiento Basado en Prefijos}: Identifica el servicio destino mediante el análisis del prefijo de la ruta URL, siguiendo convenciones claras y consistentes:
    
    \begin{itemize}
        \item /api/auth/... → Servicio de Autenticación
        \item /data-harvester/... → Servicio de Recolección de Datos
        \item /api/data/... → Servicio de Almacenamiento de Datos
        \item /data-processor/... → Servicio de Procesamiento de Datos
        \item /embedding-service/... → Servicio de Embeddings
        \item /search/... → Servicio de Búsqueda Semántica
    \end{itemize}
    
    \item \textbf{Comunicación Asíncrona}: Utiliza comunicación HTTP asíncrona mediante httpx para optimizar el rendimiento en escenarios de alta concurrencia.
    
    \item \textbf{Transparencia}: Mantiene la transparencia en el proxy, preservando encabezados, parámetros de consulta y cuerpo de las solicitudes originales.
    
    \item \textbf{Gestión de Recursos}: Implementa prácticas adecuadas para el manejo de conexiones y recursos, como el cierre apropiado del cliente HTTP al finalizar la aplicación.
\end{itemize}

Este diseño proporciona flexibilidad a la vez que mantiene la simplicidad, facilitando cambios en la topología de servicios sin afectar a los clientes externos.

\subsection{Funcionamiento del Proxy Inverso}
\label{subsec:os-proxy}

El núcleo del orquestador es la implementación del patrón de proxy inverso, que funciona según el siguiente flujo:

\begin{enumerate}
    \item \textbf{Recepción de Solicitud}: El orquestador recibe una solicitud HTTP desde un cliente externo.
    
    \item \textbf{Análisis de Ruta}: Examina el prefijo de la ruta para determinar el microservicio destino.
    
    \item \textbf{Reescritura de URL}: Modifica la URL para dirigirla al endpoint correcto en el microservicio interno.
    
    \item \textbf{Preservación de Contexto}: Mantiene los encabezados HTTP (excepto 'host'), parámetros de consulta y cuerpo de la solicitud original.
    
    \item \textbf{Envío Asíncrono}: Transmite la solicitud modificada al microservicio correspondiente de forma asíncrona.
    
    \item \textbf{Captura de Respuesta}: Recibe la respuesta del microservicio interno.
    
    \item \textbf{Transferencia Transparente}: Devuelve la respuesta al cliente con el mismo código de estado, cuerpo y encabezados.
    
    \item \textbf{Manejo de Errores}: En caso de fallos en la comunicación interna, transforma los errores en respuestas HTTP apropiadas para el cliente.
\end{enumerate}

Este mecanismo proporciona una experiencia coherente y unificada para los clientes, independientemente de la complejidad interna o la distribución de responsabilidades entre los microservicios.

\subsection{Gestión de Errores y Resiliencia}
\label{subsec:os-resiliencia}

El orquestador implementa estrategias específicas para garantizar la robustez del sistema ante diversas condiciones de error:

\begin{itemize}
    \item \textbf{Detección de Disponibilidad}: Identifica servicios no disponibles y proporciona mensajes de error claros (código 503) cuando un servicio no responde.
    
    \item \textbf{Manejo de Rutas Inválidas}: Responde con código 404 cuando se solicita un servicio que no está definido en la configuración.
    
    \item \textbf{Registro Detallado}: Documenta todos los errores de comunicación con información de contexto para facilitar el diagnóstico.
    
    \item \textbf{Propagación Controlada}: Transforma los errores internos en respuestas HTTP semánticamente correctas para los clientes.
    
    \item \textbf{Gestión de Recursos}: Implementa la liberación adecuada de recursos mediante mecanismos como BackgroundTask para evitar fugas de memoria.
\end{itemize}

Estas estrategias aseguran que, incluso ante fallos parciales, el sistema proporcione respuestas coherentes a los clientes y facilite la identificación y resolución de problemas.

\subsection{Implementación Técnica}
\label{subsec:os-implementacion}

El orquestador está implementado como una aplicación FastAPI que aprovecha las capacidades asíncronas de Python y utiliza las siguientes tecnologías clave:

\begin{itemize}
    \item \textbf{FastAPI}: Framework web de alto rendimiento que aprovecha la sintaxis de tipo de Python 3.7+ y proporciona soporte para operaciones asíncronas.
    
    \item \textbf{HTTPX}: Cliente HTTP asíncrono para Python que permite comunicaciones eficientes con otros servicios.
    
    \item \textbf{Uvicorn}: Servidor ASGI de alto rendimiento para servir la aplicación FastAPI.
    
    \item \textbf{CORS Middleware}: Componente para gestionar las políticas de Cross-Origin Resource Sharing, facilitando la integración con aplicaciones frontend.
    
    \item \textbf{Starlette}: Biblioteca subyacente que proporciona funcionalidades como BackgroundTask para la gestión eficiente de tareas de fondo.
\end{itemize}

La implementación aprovecha los beneficios de la programación asíncrona para maximizar el rendimiento en escenarios de alta concurrencia, una consideración crucial para un componente que centraliza todas las solicitudes del sistema.

\subsection{Configuración y Adaptabilidad}
\label{subsec:os-configuracion}

El orquestador está diseñado para ser altamente configurable, permitiendo adaptarse a diferentes entornos mediante variables de entorno:

\begin{itemize}
    \item \textbf{Configuración de Servicio}:
    \begin{itemize}
        \item API\_GATEWAY\_HOST: Host en el que escucha el servicio
        \item API\_GATEWAY\_PORT: Puerto de escucha
    \end{itemize}
    
    \item \textbf{Ubicación de Servicios}:
    \begin{itemize}
        \item AUTH\_SERVICE\_URL: URL del Servicio de Autenticación
        \item DATA\_HARVESTER\_URL: URL del Servicio de Recolección de Datos
        \item DATA\_STORAGE\_URL: URL del Servicio de Almacenamiento de Datos
        \item DATA\_PROCESSOR\_URL: URL del Servicio de Procesamiento de Datos
        \item EMBEDDING\_SERVICE\_URL: URL del Servicio de Embeddings
        \item SEARCH\_SERVICE\_URL: URL del Servicio de Búsqueda
    \end{itemize}
    
    \item \textbf{Configuración de Logging}:
    \begin{itemize}
        \item API\_GATEWAY\_LOG\_LEVEL: Nivel de detalle del registro
    \end{itemize}
\end{itemize}

Esta configurabilidad facilita el despliegue en diferentes entornos (desarrollo, pruebas, producción) y permite ajustar la topología de servicios sin modificar el código.

\subsection{Integración de Servicios mediante Docker Compose}
\label{subsec:os-docker-compose}

El sistema completo se despliega y gestiona mediante Docker Compose, que define la infraestructura como código y facilita la orquestación de todos los componentes. La configuración de Docker Compose proporciona:

\begin{itemize}
    \item \textbf{Definición Declarativa}: Especifica todos los servicios, sus interdependencias, redes y volúmenes en un único archivo YAML.
    
    \item \textbf{Aislamiento de Servicios}: Cada microservicio se ejecuta en su propio contenedor con un entorno controlado y definido.
    
    \item \textbf{Gestión de Dependencias}: Define el orden de inicio mediante la directiva \textit{depends\_on}, asegurando que los servicios se inicien después de sus dependencias.
    
    \item \textbf{Configuración Centralizada}: Todas las variables de entorno y parámetros de configuración se definen en un único lugar.
    
    \item \textbf{Persistencia de Datos}: Configura volúmenes Docker para garantizar la persistencia de datos críticos como la base de datos, vectores de embeddings y mensajería.
    
    \item \textbf{Networking}: Establece una red interna (\textit{semantic-search-network}) que permite la comunicación entre servicios utilizando nombres de host consistentes.
    
    \item \textbf{Health Checks}: Implementa verificaciones de salud para servicios críticos como MySQL y RabbitMQ, asegurando que los servicios dependientes solo se inicien cuando estos estén completamente operativos.
    
    \item \textbf{Gestión de Recursos}: Configura reservas de recursos específicos, como GPU para los servicios de embeddings y búsqueda que requieren procesamiento de modelos de lenguaje.
    
    \item \textbf{Exposición Controlada}: Solo expone al exterior los puertos necesarios (principalmente el puerto 8000 del orquestador), manteniendo los demás servicios accesibles únicamente dentro de la red interna.
\end{itemize}

La configuración de Docker Compose facilita significativamente la gestión del ciclo de vida completo del sistema, desde el desarrollo hasta la producción, y permite escalar horizontal y verticalmente según las necesidades.

\subsection{Arquitectura del Sistema Completo}
\label{subsec:os-arquitectura-completa}

La integración del orquestador con el resto de los microservicios forma una arquitectura completa y cohesiva, con las siguientes características:

\begin{itemize}
    \item \textbf{Estructura en Capas}: El sistema se organiza en capas funcionales:
    
    \begin{itemize}
        \item \textit{Capa de Acceso}: Orquestador (API Gateway)
        \item \textit{Capa de Seguridad}: Servicio de Autenticación
        \item \textit{Capa de Datos}: Servicios de Recolección, Almacenamiento y Procesamiento
        \item \textit{Capa de Procesamiento Semántico}: Servicios de Embedding y Búsqueda
        \item \textit{Capa de Persistencia}: MySQL y ChromaDB
        \item \textit{Capa de Mensajería}: RabbitMQ
    \end{itemize}
    
    \item \textbf{Comunicación Síncrona y Asíncrona}: Combina comunicación sincrónica (HTTP) para operaciones orientadas a solicitud-respuesta y asíncrona (RabbitMQ) para procesamiento en segundo plano y notificaciones de eventos.
    
    \item \textbf{Independencia de Servicios}: Cada servicio mantiene su propio ciclo de vida y puede evolucionar independientemente, comunicándose a través de interfaces bien definidas.
    
    \item \textbf{Contención de Fallos}: El aislamiento de servicios evita que los fallos se propaguen en cascada por todo el sistema.
    
    \item \textbf{Especialización}: Cada servicio se enfoca en un dominio específico, siguiendo el principio de responsabilidad única.
\end{itemize}

Esta arquitectura proporciona un equilibrio entre cohesión (a través del orquestador) y desacoplamiento (mediante servicios especializados), resultando en un sistema que es tanto robusto como adaptable.

\subsection{Sustitución del Orquestador por Herramientas No-Code}
\label{subsec:os-nocode}

Una característica distintiva del diseño actual es la posibilidad de reemplazar el orquestador basado en código por plataformas no-code como n8n, lo que ofrece ventajas significativas en ciertos escenarios:

\begin{itemize}
    \item \textbf{Viabilidad de la Sustitución}: El orquestador actual implementa principalmente funciones de enrutamiento y proxy, que pueden ser reproducidas a través de herramientas no-code especializadas en integración de APIs.
    
    \item \textbf{Ventajas Potenciales}:
    \begin{itemize}
        \item \textit{Configuración Visual}: n8n proporciona una interfaz visual para definir flujos de trabajo y rutas de API, reduciendo la barrera de entrada para usuarios no técnicos.
        
        \item \textit{Adaptabilidad Rápida}: Permite modificar flujos de integración sin necesidad de recompilar y redesplegar código.
        
        \item \textit{Integración Expandida}: Facilita la conexión con servicios externos aprovechando los cientos de conectores preexistentes en plataformas como n8n.
        
        \item \textit{Monitorización Visual}: Proporciona dashboards y visualizaciones para supervisar el funcionamiento del sistema.
        
        \item \textit{Lógica Condicional}: Permite implementar reglas de negocio y transformaciones sin escribir código.
    \end{itemize}
    
    \item \textbf{Implementación Práctica}: Para reemplazar el orquestador actual con n8n, se seguiría este proceso:
    
    \begin{itemize}
        \item Desplegar n8n como un servicio adicional en la configuración de Docker Compose.
        
        \item Configurar los workflows en n8n que repliquen las funciones de proxy del orquestador, definiendo nodos HTTP que escuchen en los endpoints correspondientes y redirijan al servicio interno apropiado.
        
        \item Establecer transformaciones para preservar encabezados, parámetros y cuerpo de las solicitudes.
        
        \item Configurar manejo de errores y respuestas para mantener la transparencia hacia los clientes.
        
        \item Actualizar la configuración de red para exponer n8n en lugar del orquestador original.
    \end{itemize}
    
    \item \textbf{Consideraciones}: Esta sustitución debe evaluar factores como:
    
    \begin{itemize}
        \item \textit{Rendimiento}: Las plataformas no-code pueden introducir cierta sobrecarga en comparación con implementaciones de código nativo.
        
        \item \textit{Escalabilidad}: Verificar que la plataforma elegida pueda manejar el volumen esperado de solicitudes.
        
        \item \textit{Seguridad}: Asegurar que la plataforma no-code mantenga o mejore las salvaguardas de seguridad existentes.
        
        \item \textit{Control de Versiones}: Implementar estrategias para gestionar versiones de los flujos de trabajo visuales.
    \end{itemize}
\end{itemize}

La posibilidad de sustituir el orquestador por herramientas no-code demuestra la flexibilidad del diseño del sistema y abre oportunidades para adaptarse a diferentes necesidades organizacionales y técnicas.

\subsection{Extensibilidad y Evolución Futura}
\label{subsec:os-extension}

El diseño del orquestador y la arquitectura general del sistema facilitan su evolución futura en varias direcciones:

\begin{itemize}
    \item \textbf{API Management Avanzado}: Evolución hacia capacidades completas de gestión de API, incluyendo:
    \begin{itemize}
        \item Rate limiting y throttling a nivel de cliente
        \item Versionado de API
        \item Documentación automática y sandboxing para pruebas
        \item Monetización y planes de consumo
    \end{itemize}
    
    \item \textbf{Observabilidad Mejorada}: Incorporación de telemetría avanzada:
    \begin{itemize}
        \item Distributed tracing para seguimiento de solicitudes entre servicios
        \item Métricas detalladas de rendimiento y utilización
        \item Dashboards en tiempo real para monitoreo operativo
    \end{itemize}
    
    \item \textbf{Patrones de Comunicación}: Expansión de los modelos de interacción:
    \begin{itemize}
        \item Soporte para streaming de datos
        \item Implementación de WebSockets para comunicación bidireccional
        \item Event sourcing para propagación consistente de cambios
    \end{itemize}
    
    \item \textbf{Transformación y Enriquecimiento}: Capacidades para modificar dinámicamente las solicitudes y respuestas:
    \begin{itemize}
        \item Agregación de respuestas de múltiples servicios
        \item Transformación de formatos de datos
        \item Enriquecimiento contextual de solicitudes
    \end{itemize}
    
    \item \textbf{Despliegue Distribuido}: Evolución hacia modelos de despliegue más sofisticados:
    \begin{itemize}
        \item Arquitectura de malla de servicios (service mesh)
        \item Despliegue multi-región con latencia optimizada
        \item Estrategias avanzadas de resiliencia como circuit breaker y bulkhead
    \end{itemize}
\end{itemize}

La modularidad inherente al diseño del sistema y la centralización del enrutamiento en el orquestador proporcionan una base sólida para incorporar estas mejoras de forma incremental sin disrupciones significativas.

\section{Conclusiones y Trabajo Futuro}
\label{sec:conclusiones}

El sistema de identificación de personas mediante similitud semántica representa un avance significativo en la aplicación de tecnologías de procesamiento de lenguaje natural para el análisis de descripciones textuales. A lo largo de este artículo, hemos presentado una arquitectura completa, basada en microservicios especializados, que aborda los desafíos técnicos inherentes a esta tarea.

\subsection{Contribuciones Principales}
\label{subsec:contribuciones}

Las contribuciones más destacadas de este trabajo incluyen:

\begin{itemize}
    \item Una arquitectura modular y descentralizada que permite el desarrollo, escalado y mantenimiento independiente de cada componente funcional.
    
    \item Un enfoque sofisticado para la búsqueda semántica que aprovecha modelos de embeddings preentrenados, permitiendo identificar similitudes significativas incluso cuando las descripciones utilizan vocabulario diferente.
    
    \item Mecanismos robustos de autenticación y autorización que garantizan la seguridad e integridad de los datos procesados.
    
    \item Un sistema de orquestación flexible que facilita la integración de los diferentes servicios y permite una evolución gradual de la plataforma.
    
    \item Estrategias de almacenamiento optimizadas para datos vectoriales que permiten búsquedas eficientes en espacios de alta dimensionalidad.
    
    \item Mecanismos de comunicación inter-servicios que combinan paradigmas síncronos y asíncronos según las necesidades específicas de cada interacción.
\end{itemize}

\subsection{Limitaciones Actuales}
\label{subsec:limitaciones}

A pesar de los avances logrados, reconocemos ciertas limitaciones en la implementación actual:

\begin{itemize}
    \item La dependencia de modelos de embeddings preentrenados limita la adaptabilidad a dominios altamente especializados sin un proceso de fine-tuning.
    
    \item La necesidad de mantener índices vectoriales en memoria para búsquedas eficientes impone requisitos significativos de recursos en despliegues a gran escala.
    
    \item La arquitectura actual no aborda completamente escenarios de recuperación ante desastres y continuidad de operaciones en entornos geográficamente distribuidos.
    
    \item Los mecanismos de feedback para mejorar gradualmente la precisión de las búsquedas semánticas son aún rudimentarios.
\end{itemize}

\subsection{Trabajo Futuro}
\label{subsec:trabajo-futuro}

Basándonos en los resultados obtenidos y las limitaciones identificadas, proponemos las siguientes líneas de trabajo futuro:

\begin{itemize}
    \item \textbf{Modelos Adaptables}: Implementación de mecanismos de fine-tuning continuo que permitan adaptar los modelos de embeddings a vocabularios y contextos específicos.
    
    \item \textbf{Procesamiento Multimodal}: Extensión del sistema para incorporar información multimodal, integrando descripciones textuales con datos biométricos, imágenes y otros tipos de información.
    
    \item \textbf{Explicabilidad}: Desarrollo de capacidades para explicar las decisiones de similitud, identificando qué características específicas de las descripciones contribuyeron a la determinación de semejanza.
    
    \item \textbf{Federación de Sistemas}: Implementación de mecanismos para la búsqueda federada entre múltiples instancias del sistema, permitiendo la colaboración entre organizaciones sin centralizar todos los datos.
    
    \item \textbf{Optimización de Recursos}: Exploración de técnicas avanzadas para reducir la dimensionalidad de los embeddings y optimizar el uso de memoria sin comprometer significativamente la precisión.
    
    \item \textbf{Evaluación Sistemática}: Desarrollo de benchmarks específicos para evaluar rigurosamente el rendimiento del sistema en escenarios realistas de identificación de personas.
\end{itemize}

\subsection{Reflexión Final}
\label{subsec:reflexion}

El sistema presentado representa un punto de equilibrio entre la sofisticación técnica necesaria para abordar la complejidad inherente al procesamiento semántico y la aplicabilidad práctica en escenarios reales. La arquitectura modular, centrada en microservicios especializados y orquestados eficientemente, proporciona una base sólida para la evolución continua y la adaptación a nuevos requisitos y tecnologías emergentes.

El potencial de impacto de este sistema en ámbitos como seguridad pública, investigación forense y atención ciudadana es significativo, ofreciendo capacidades que hasta hace poco eran exclusivas del juicio humano: la identificación de similitudes significativas en descripciones textuales imprecisas o incompletas. Continuaremos refinando y expandiendo estas capacidades, buscando cerrar la brecha entre la comprensión humana y computacional del lenguaje natural en el contexto específico de la identificación de personas.

\end{document} 